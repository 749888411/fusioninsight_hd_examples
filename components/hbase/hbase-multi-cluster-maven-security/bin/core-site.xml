<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<configuration>
<property>
<name>hadoop.http.authentication.logout</name>
<value>https://160.133.0.177:20027/cas/logout</value>
</property>
<property>
<name>hadoop.proxyuser.spark.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.http.filter.initializers</name>
<value>com.huawei.hadoop.datasight.FlowCtrlFilter,com.huawei.hadoop.datasight.XSSFilterInitializer,com.huawei.hadoop.datasight.InternalSpnegoFilter,com.huawei.hadoop.datasight.CASClientFilter,com.huawei.hadoop.datasight.LogoutFilterInitializer</value>
</property>
<property>
<name>hadoop.proxyuser.hive.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.ssl.hostname.verifier</name>
<value>DEFAULT</value>
</property>
<property>
<name>hadoop.security.authorization</name>
<value>true</value>
</property>
<property>
<name>hadoop.proxyuser.mapred.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.hue.hosts</name>
<value>*</value>
</property>
<property>
<name>hadoop.http.server.MaxRequests</name>
<value>2000</value>
</property>
<property>
<name>hadoop.ssl.keystores.factory.class</name>
<value>org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory</value>
</property>
<property>
<name>ha.zookeeper.session-timeout.ms</name>
<value>45000</value>
</property>
<property>
<name>hadoop.proxyuser.loader.hosts</name>
<value>*</value>
</property>
<property>
<name>hadoop.ssl.require.client.cert</name>
<value>false</value>
</property>
<property>
<name>hadoop.security.authentication</name>
<value>kerberos</value>
</property>
<property>
<name>fs.defaultFS</name>
<value>hdfs://hacluster</value>
</property>
<property>
<name>zookeeper.kerberos.principal</name>
<value>zookeeper/hadoop.hadoop.com</value>
</property>
<property>
<name>hadoop.ssl.server.conf</name>
<value>ssl-server.xml</value>
</property>
<property>
<name>hadoop.proxyuser.thrift.hosts</name>
<value>*</value>
</property>
<property>
<name>dfs.encrypt.data.transfer</name>
<value>false</value>
</property>
<property>
<name>hadoop.proxyuser.mapred.hosts</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.spark.hosts</name>
<value>*</value>
</property>
<property>
<name>hadoop.security.crypto.implementation.class</name>
<value>com.huawei.hadoop.datasight.security.FMHadoopCryptAdapter</value>
</property>
<property>
<name>hadoop.proxyuser.loader.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.hue.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.spnego.allowed.ips</name>
<value>.*</value>
</property>
<property>
<name>hadoop.proxyuser.thrift.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.hive.hosts</name>
<value>*</value>
</property>
<property>
<name>hadoop.http.authentication.center</name>
<value>https://160.133.0.177:20027/cas/</value>
</property>
<property>
<name>hbase.kerberos.principal</name>
<value>hbase/hadoop.hadoop.com@HADOOP.COM</value>
</property>
<property>
<name>hadoop.http.kerberos.internal.spnego.principal</name>
<value>hbase/hadoop.hadoop.com@HADOOP.COM</value>
</property>
<property>
<name>hadoop.security.auth_to_local</name>
<value>RULE:[1:$1@$0](^.*@HDFS\.COM$)s/^(.*)@HDFS\.COM$/$1/g
                    RULE:[2:$1@$0](^.*@HDFS\.COM$)s/^(.*)@HDFS\.COM$/$1/g
                    DEFAULT</value>
</property>
<property>
<name>hadoop.http.server.name</name>
<value>https://160-133-0-22:21301</value>
</property>
<property>
<name>hadoop.rpc.protection</name>
<value>privacy</value>
</property>
</configuration>
